{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781db93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from  pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ea47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_whatsapp_chat(file_path: str) -> pd.DataFrame:\n",
    "    # Define filtering patterns\n",
    "    encryption_message = \"Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more.\"\n",
    "    media_pattern = \"<Media omitted>\"\n",
    "    email_pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}'\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    edited_message = \"<This message was edited>\"\n",
    "    deleted_message = \"You deleted this message\"\n",
    "    null_message = \"null\"\n",
    "    created_group_message = \"created group\"\n",
    "    added_you_to_group_message = \"added you\"\n",
    "    tagging_pattern = r'@[\\w]+'\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Apply filters to remove unwanted lines\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        if (\n",
    "            encryption_message not in line and\n",
    "            deleted_message not in line and\n",
    "            null_message != line.split(\" \")[-1] and\n",
    "            media_pattern not in line and\n",
    "            created_group_message not in line and\n",
    "            added_you_to_group_message not in line and\n",
    "            not re.search(email_pattern, line) and\n",
    "            not re.search(url_pattern, line)\n",
    "        ):\n",
    "            line = line.replace(edited_message, \"\").strip()\n",
    "            line = re.sub(tagging_pattern, \"\", line).strip()\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    # Normalize content:\n",
    "    content = '\\n'.join(filtered_lines)\n",
    "    # Replace narrow no-break space (iOS specific)\n",
    "    content = content.replace('\\u202f', ' ')\n",
    "    # Remove square brackets if they surround the timestamp (only for iOS)\n",
    "    content = re.sub(\n",
    "        r'\\[(\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}(?::\\d{2})?\\s?[APap][Mm])\\]',\n",
    "        r'\\1',\n",
    "        content\n",
    "    )\n",
    "    # Remove LRM and RLM characters (Left-to-Right Mark and Right-to-Left Mark)\n",
    "    content = content.replace('\\u200E', '').replace('\\u200F', '')\n",
    "\n",
    "    # Updated regex pattern to match both iOS and Android WhatsApp exports.\n",
    "    pattern = r'(\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}(?::\\d{2})?(?:\\s?[APap][Mm])?)\\s?(?:-|\\~)?\\s?(.*?): (.*?)(?=\\n\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2}|$)'\n",
    "    messages = re.findall(pattern, content, re.DOTALL)\n",
    "    df = pd.DataFrame(messages, columns=['timestamp', 'sender', 'message'])\n",
    "\n",
    "    timestamps = []\n",
    "    for timestamp in df['timestamp']:\n",
    "        try:\n",
    "            timestamp = pd.to_datetime(\n",
    "                timestamp, format='mixed', errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamp '{timestamp}': {e}\")\n",
    "            timestamp = pd.NaT\n",
    "        timestamps.append(timestamp)\n",
    "\n",
    "    df['timestamp'] = timestamps\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85646d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_41704\\1343640759.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data_path=Path(\"Data\\private\")\n"
     ]
    }
   ],
   "source": [
    "all_chats={}\n",
    "data_path=Path(\"Data\\private\")\n",
    "for file in data_path.glob(\"*.txt\"):\n",
    "    chat_name=file.stem\n",
    "    all_chats[chat_name]=read_whatsapp_chat(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6836999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 349552 characters\n"
     ]
    }
   ],
   "source": [
    "text_seq=\"\"\n",
    "for file_name in all_chats.keys():\n",
    "    text_seq+=''.join(all_chats[file_name]['message'].values)\n",
    "\n",
    "print(f\"Length of text: {len(text_seq)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77be3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/combined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de621815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_41704\\3702855359.py:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  input='outputs\\combined_text.txt',\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='outputs\\combined_text.txt',\n",
    "    model_prefix='spm_model',\n",
    "    vocab_size=5762,\n",
    "    model_type='unigram',   # or 'bpe', 'word'\n",
    "    character_coverage=0.9995,\n",
    "    pad_id=0, unk_id=1, bos_id=2, eos_id=3,\n",
    "    user_defined_symbols='[MASK]'\n",
    ")\n",
    "# This writes spm_model.model and spm_model.vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94f165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199, 51, 441, 22, 218]\n",
      "My name is Shree\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"spm_model.model\")\n",
    "\n",
    "# Encode text into IDs\n",
    "ids = sp.encode(\"My name is Shree\")\n",
    "print(ids)   \n",
    "\n",
    "# Decode IDs back into text\n",
    "text = sp.decode(ids)\n",
    "print(text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd7800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "dim: int = 512\n",
    "n_layers: int = 8\n",
    "n_heads: int = 8\n",
    "vocab_size: int = 5762\n",
    "ffn_dim_multiplier: 4\n",
    "norm_eps: float = 1e-5\n",
    "dropout=0.2\n",
    "# Needed for KV cache\n",
    "max_batch_size: int = 32\n",
    "context_length: int = 256\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available()  else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47cbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# Set device and context_length\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "context_length = 256\n",
    "vocab_size = 5762\n",
    "\n",
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, sequence_length: int, d_model: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.sequence_length = sequence_length\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(sequence_length, d_model)\n",
    "        pos = torch.arange(0, sequence_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        # Register as buffer so it moves with .to(device)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.shape[1], :].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x: torch.Tensor):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        output = self._norm(x.float())\n",
    "        # self.weight will be on the same device as x after model.to(device)\n",
    "        return self.weight * output.type_as(x)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float, ff=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.ffw = nn.Sequential(\n",
    "            nn.Linear(d_model, ff * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff * d_model, d_model),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.ffw(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, n_head: int, dropout: float, context_length: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = n_head\n",
    "        assert d_model % n_head == 0, 'd_model is not divisible by the no. of heads'\n",
    "        \n",
    "        self.dk = d_model // self.h\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Register as buffer so it moves with .to(device)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length, context_length)))\n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        dk = query.shape[-1]\n",
    "        attention_scores = (query @ key.transpose(-1, -2)) / math.sqrt(dk)\n",
    "        \n",
    "        T = query.shape[-2]\n",
    "        attention_scores = attention_scores.masked_fill(mask[:T, :T] == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim=-1)\n",
    "        \n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "        \n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        key = self.w_k(k)\n",
    "        query = self.w_q(q)\n",
    "        value = self.w_v(v)\n",
    "\n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.dk).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.dk).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.dk).transpose(1, 2)\n",
    "\n",
    "        x, self.attention_scores = self.attention(query, key, value, self.tril, self.dropout)\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.dk)\n",
    "        return self.w_o(x)\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, dropout: float, d_model: int):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = RMSNorm(d_model)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, cross_multihead_attention: MultiHeadAttention, \n",
    "                 feed_forward: FeedForward, dropout: float, d_model: int):\n",
    "        super().__init__()\n",
    "        self.cross_multihead_attention = cross_multihead_attention\n",
    "        self.feed_forward = feed_forward\n",
    "        self.dropout = dropout\n",
    "        # Only 2 residual connections in a decoder-only block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout, d_model) for _ in range(2)]) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_connections[0](x, lambda x: self.cross_multihead_attention(x, x, x))\n",
    "        x = self.residual_connections[1](x, self.feed_forward)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layers: nn.ModuleList, d_model: int):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "\n",
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.proj = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, seq_length: int,\n",
    "                 d_model=512, n_layers=6, n_heads=8, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.token_embd = InputEmbedding(vocab_size, d_model)\n",
    "        self.pos_emd = PositionalEmbedding(seq_length, d_model, dropout)\n",
    "        \n",
    "        decoder_blocks = []\n",
    "        for _ in range(n_layers):\n",
    "            decoder_cross_attention = MultiHeadAttention(d_model, n_heads, dropout, seq_length)\n",
    "            ffw = FeedForward(d_model, dropout)\n",
    "            decoder_block = DecoderBlock(decoder_cross_attention, ffw, dropout, d_model)\n",
    "            decoder_blocks.append(decoder_block)\n",
    "        \n",
    "        self.decoder = Decoder(nn.ModuleList(decoder_blocks), d_model)\n",
    "        self.rms = RMSNorm(d_model)\n",
    "        self.proj_layer = ProjectionLayer(d_model, vocab_size)\n",
    "\n",
    "\n",
    "    def _init_weights(self, module: nn.Module) -> None:\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, input_tokens,targets: Optional[torch.Tensor] = None):\n",
    "        B, T = input_tokens.shape\n",
    "        t_emb = self.token_embd(input_tokens)\n",
    "        x = self.pos_emd(t_emb)\n",
    "        x = self.decoder(x)\n",
    "        x = self.rms(x)\n",
    "        logits = self.proj_layer(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "    \n",
    "\n",
    "\n",
    "    def generate(self, input_tokens: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "                Generate new tokens given a context.\n",
    "\n",
    "                Args:\n",
    "                        input_tokens: Starting token indices of shape (batch_size, sequence_length)\n",
    "                        max_new_tokens: Number of new tokens to generate\n",
    "\n",
    "                Returns:\n",
    "                        Tensor of token indices of shape (batch_size, sequence_length + max_new_tokens)\n",
    "                \"\"\"\n",
    "\n",
    "        # input_tokens is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop input_tokens to the last block_size tokens\n",
    "            cropped_input = input_tokens[:, -context_length:]\n",
    "            # get the predictions\n",
    "            logits, _ = self(cropped_input)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            input_tokens = torch.cat(\n",
    "                (input_tokens, idx_next), dim=1)  # (B, T+1)\n",
    "        return input_tokens\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2dab8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 256, 5762])\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(vocab_size=vocab_size, seq_length=context_length,\n",
    "                        d_model=512, n_layers=6, n_heads=8, dropout=0.2)\n",
    "\n",
    "# Move model to device\n",
    "model = transformer.to(device)\n",
    "# Create input and move to device\n",
    "x= torch.randint(0, vocab_size, (1, context_length)).to(device)\n",
    "\n",
    "# Forward pass\n",
    "output,_ = model(x)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Device: {output.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f751029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.803458 M para\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M para')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e96c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\shree\\AppData\\Local\\Temp\\ipykernel_41704\\1466599194.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  with open('outputs\\combined_text.txt','r') as f:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110189"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('outputs\\combined_text.txt','r') as f:\n",
    "    text_sequence=f.read()\n",
    "\n",
    "encoded_text_sequence=sp.Encode(text_sequence)\n",
    "len(encoded_text_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c8d0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.tensor(encoded_text_sequence,dtype=torch.long)\n",
    "split_index=int(0.95*len(data))\n",
    "train_data=data[:split_index]\n",
    "test_data=data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70a348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 256]), torch.Size([256, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def get_batch(split: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    index = torch.randint(len(data) - context_length, (context_length,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in index])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in index])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6f1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size: int) -> None:\n",
    "        if len(data) <= block_size:\n",
    "            raise ValueError(\n",
    "                f\"The length of the data ({len(data)}) must be greater than the block_size ({block_size}).\"\n",
    "            )\n",
    "\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.data[index : index + self.block_size]\n",
    "        y = self.data[index + 1 : index + self.block_size + 1]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def get_dataloaders(\n",
    "    train_data: torch.Tensor,\n",
    "    val_data: torch.Tensor,\n",
    "    block_size: int,\n",
    "    batch_size: int,\n",
    "    device: torch.device,\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train_dataset = TextDataset(train_data.to(device), block_size)\n",
    "    val_dataset = TextDataset(val_data.to(device), block_size)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b1327b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 256]), torch.Size([64, 256]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_data=train_data,\n",
    "    val_data=test_data,\n",
    "    block_size=context_length,\n",
    "    batch_size=64,\n",
    "    device=device,\n",
    ")\n",
    "x, y = next(iter(train_loader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904e745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    eval_iters: int\n",
    ") -> Dict[str, float]:\n",
    "    output = {}\n",
    "    model.eval()\n",
    "\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            if i >= eval_iters:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                _,loss= model(x,y)\n",
    "            losses[i] = loss.item()\n",
    "        output[split] = losses.mean().item()\n",
    "\n",
    "    model.train()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "602cf81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: Transformer,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    file_path: str = \"checkpoint.pth\"\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11f2b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / step 0: train loss 0.0520, val loss 14.3975\n",
      "iteration 0 / step 100: train loss 0.0533, val loss 14.4768\n",
      "iteration 0 / step 200: train loss 0.0527, val loss 14.4306\n",
      "iteration 0 / step 300: train loss 0.0507, val loss 14.5233\n",
      "iteration 0 / step 400: train loss 0.0500, val loss 14.5608\n",
      "iteration 0 / step 500: train loss 0.0510, val loss 14.4755\n",
      "iteration 0 / step 600: train loss 0.0524, val loss 14.5216\n",
      "iteration 0 / step 700: train loss 0.0502, val loss 14.5631\n",
      "iteration 0 / step 800: train loss 0.0507, val loss 14.5208\n",
      "iteration 0 / step 900: train loss 0.0516, val loss 14.6094\n",
      "iteration 0 / step 1000: train loss 0.0502, val loss 14.5357\n",
      "iteration 0 / step 1100: train loss 0.0487, val loss 14.5504\n",
      "iteration 0 / step 1200: train loss 0.0488, val loss 14.6517\n",
      "iteration 0 / step 1300: train loss 0.0490, val loss 14.7099\n",
      "iteration 0 / step 1400: train loss 0.0492, val loss 14.6438\n",
      "iteration 0 / step 1500: train loss 0.0481, val loss 14.5984\n",
      "iteration 0 / step 1600: train loss 0.0484, val loss 14.6562\n",
      "iteration 0 / step 1631: train loss 0.0478, val loss 14.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [32:41<32:41, 1961.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 / step 0: train loss 0.0479, val loss 14.6487\n",
      "iteration 1 / step 100: train loss 0.0478, val loss 14.7414\n",
      "iteration 1 / step 200: train loss 0.0478, val loss 14.7954\n",
      "iteration 1 / step 300: train loss 0.0481, val loss 14.7632\n",
      "iteration 1 / step 400: train loss 0.0480, val loss 14.7619\n",
      "iteration 1 / step 500: train loss 0.0466, val loss 14.7792\n",
      "iteration 1 / step 600: train loss 0.0473, val loss 14.7389\n",
      "iteration 1 / step 700: train loss 0.0468, val loss 14.7211\n",
      "iteration 1 / step 800: train loss 0.0474, val loss 14.8516\n",
      "iteration 1 / step 900: train loss 0.0460, val loss 14.8870\n",
      "iteration 1 / step 1000: train loss 0.0475, val loss 14.9961\n",
      "iteration 1 / step 1100: train loss 0.0451, val loss 14.9714\n",
      "iteration 1 / step 1200: train loss 0.0447, val loss 14.9392\n",
      "iteration 1 / step 1300: train loss 0.0461, val loss 14.9477\n",
      "iteration 1 / step 1400: train loss 0.0454, val loss 14.9138\n",
      "iteration 1 / step 1500: train loss 0.0455, val loss 14.8850\n",
      "iteration 1 / step 1600: train loss 0.0459, val loss 14.9810\n",
      "iteration 1 / step 1631: train loss 0.0458, val loss 15.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [1:05:27<1:05:27, 3927.87s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ../output/pre_training/run_4 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Save checkpoint\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     save_checkpoint(\n\u001b[0;32m     40\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     41\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     42\u001b[0m         epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m     43\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m     44\u001b[0m         file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../output/pre_training/run_4/checkpoint_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m, in \u001b[0;36msave_checkpoint\u001b[1;34m(model, optimizer, epoch, loss, file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_checkpoint\u001b[39m(\n\u001b[0;32m      2\u001b[0m     model: Transformer,\n\u001b[0;32m      3\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     file_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: optimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\n\u001b[0;32m     13\u001b[0m     }\n\u001b[1;32m---> 14\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(checkpoint, file_path)\n",
      "File \u001b[1;32mc:\\Users\\shree\\anaconda3\\envs\\deepenv3\\Lib\\site-packages\\torch\\serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    850\u001b[0m         _save(\n\u001b[0;32m    851\u001b[0m             obj,\n\u001b[0;32m    852\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    856\u001b[0m         )\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shree\\anaconda3\\envs\\deepenv3\\Lib\\site-packages\\torch\\serialization.py:716\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mc:\\Users\\shree\\anaconda3\\envs\\deepenv3\\Lib\\site-packages\\torch\\serialization.py:687\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ../output/pre_training/run_4 does not exist."
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "eval_interval = 100\n",
    "eval_iters = 200\n",
    "learning_rate = 3e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Evaluation\n",
    "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "            losses = estimate_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                eval_iters=min(eval_iters, len(val_loader))\n",
    "            )\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "\n",
    "            print(\n",
    "                f\"iteration {epoch} / step {batch_idx}: \"\n",
    "                f\"train loss {losses['train']:.4f}, \"\n",
    "                f\"val loss {losses['val']:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Training step\n",
    "        logits, loss = model(x_batch, y_batch)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch==1:\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            loss=loss.item(),\n",
    "            file_path=f\"outputs/pre_training/run_4/checkpoint_{epoch}.pth\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5b8cf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "save_checkpoint(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    epoch=epoch,\n",
    "    loss=loss.item(),\n",
    "    file_path=f\"C:/Users/shree/OneDrive/Documents/Trasnformer_architecture/outputs/checkpoint_{epoch}.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd389593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "# plt.plot(val_losses, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel(\"Evaluation Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "650ab091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clg hain?Haan\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"clg hain?\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=1)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "5df87882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postal code mumbai 400088\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"postal code mumbai\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=1)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "82ef0236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper ka working part karna hai tohI hav\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"paper\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=9)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "58fc8e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "araha hain?nahiOm bhai bohot traffic hain and train bhi\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"araha hain?\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=10)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "596e10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in hain kya?Haan\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"in hain kya?\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=1)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "ff68def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code💀Let's try 🫡😂Bruh imma tryAlso if ur doing local pc pe then use torch.amppehle ye run karta hu kal shaam ko30 percent reduction guaranteedHaan\n"
     ]
    }
   ],
   "source": [
    "input_tokens = sp.Encode(\"code\")\n",
    "input_tokens = torch.tensor(\n",
    "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tokens=input_tokens, max_new_tokens=50)\n",
    "\n",
    "print(sp.Decode(output[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
